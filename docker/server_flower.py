#!/usr/bin/env python3
"""
PromptFL with Flower - Docker Server
åŸºäºå½“å‰å®Œæ•´ç‰ˆæœ¬çš„Docker serverå®ç°
"""

import os
import sys
from pathlib import Path
import argparse
import logging
import time

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['FLWR_TELEMETRY_ENABLED'] = '0'

# ç¦ç”¨TensorFlowç›¸å…³çš„å¯¼å…¥
sys.modules['tensorflow'] = None
sys.modules['tensorboard'] = None

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

import flwr as fl
import torch
import numpy as np
from typing import Dict, List, Tuple, Optional, Any

# å¯¼å…¥æˆ‘ä»¬çš„ç»„ä»¶
from config_flower import get_cfg_default, extend_cfg
from trainers.promptfl_flower import PromptFLFlower
from trainers.baseline import BaselineFlower
from trainers.coop import CoOpFlower
from utils_flower import average_weights

# Trainer registry
TRAINER_REGISTRY = {
    "PromptFL": PromptFLFlower,
    "Baseline": BaselineFlower,
    "CoOp": CoOpFlower,
}

def build_trainer(cfg):
    """Build trainer based on config"""
    trainer_name = cfg.TRAINER.NAME
    if trainer_name not in TRAINER_REGISTRY:
        raise ValueError(f"Unknown trainer: {trainer_name}. Available: {list(TRAINER_REGISTRY.keys())}")
    
    trainer_class = TRAINER_REGISTRY[trainer_name]
    return trainer_class(cfg)

class PromptFLStrategy(fl.server.strategy.FedAvg):
    """PromptFLè”é‚¦å­¦ä¹ ç­–ç•¥"""
    
    def __init__(self, cfg, **kwargs):
        self.cfg = cfg
        self.trainer = build_trainer(cfg)
        
        # åˆå§‹åŒ–å…¨å±€æ¨¡å‹
        self.trainer.fed_before_train(is_global=True)
        
        super().__init__(**kwargs)
        
        print(f"ğŸŒ¸ PromptFL Strategy initialized")
        print(f"   Trainer: {cfg.TRAINER.NAME}")
        print(f"   Dataset: {cfg.DATASET.NAME}")
        print(f"   Backbone: {cfg.MODEL.BACKBONE.NAME}")
        print(f"   Users: {cfg.DATASET.USERS}")
        print(f"   Rounds: {cfg.OPTIM.ROUND}")
    
    def initialize_parameters(self, client_manager):
        """åˆå§‹åŒ–å…¨å±€å‚æ•°"""
        # è·å–åˆå§‹å‚æ•°
        initial_params = self.trainer.model.state_dict()
        
        # è½¬æ¢ä¸ºFlowerå‚æ•°æ ¼å¼
        params_list = []
        for key, value in initial_params.items():
            if 'prompt_learner' in key:  # åªä¼ è¾“promptå‚æ•°
                params_list.append(value.cpu().numpy())
        
        return fl.common.ndarrays_to_parameters(params_list)
    
    def aggregate_fit(self, server_round, results, failures):
        """èšåˆè®­ç»ƒç»“æœ"""
        if not results:
            return None, {}
        
        print(f"\nğŸ”„ Round {server_round}: Aggregating {len(results)} client updates")
        
        # æå–å‚æ•°å’ŒæŒ‡æ ‡
        weights_results = [
            (fl.common.parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)
            for _, fit_res in results
        ]
        
        # èšåˆå‚æ•°
        aggregated_weights = self.aggregate_weights(weights_results)
        
        # æ›´æ–°å…¨å±€æ¨¡å‹
        self.update_global_model(aggregated_weights)
        
        # èšåˆæŒ‡æ ‡
        metrics = {}
        if results:
            total_examples = sum([fit_res.num_examples for _, fit_res in results])
            
            # è®¡ç®—åŠ æƒå¹³å‡æŒ‡æ ‡
            for metric_name in ['train_loss', 'train_accuracy']:
                if all(metric_name in fit_res.metrics for _, fit_res in results):
                    weighted_sum = sum([
                        fit_res.metrics[metric_name] * fit_res.num_examples 
                        for _, fit_res in results
                    ])
                    metrics[metric_name] = weighted_sum / total_examples
        
        print(f"   ğŸ“Š Aggregated metrics: {metrics}")
        
        return fl.common.ndarrays_to_parameters(aggregated_weights), metrics
    
    def aggregate_weights(self, weights_results):
        """èšåˆæƒé‡"""
        # è®¡ç®—æ€»æ ·æœ¬æ•°
        total_examples = sum([num_examples for _, num_examples in weights_results])
        
        # åŠ æƒå¹³å‡
        aggregated = None
        for weights, num_examples in weights_results:
            weight = num_examples / total_examples
            
            if aggregated is None:
                aggregated = [w * weight for w in weights]
            else:
                for i, w in enumerate(weights):
                    aggregated[i] += w * weight
        
        return aggregated
    
    def update_global_model(self, aggregated_weights):
        """æ›´æ–°å…¨å±€æ¨¡å‹"""
        # æ›´æ–°æ¨¡å‹å‚æ•°
        state_dict = self.trainer.model.state_dict()
        param_idx = 0
        
        for key, value in state_dict.items():
            if 'prompt_learner' in key:
                if param_idx < len(aggregated_weights):
                    state_dict[key] = torch.from_numpy(aggregated_weights[param_idx])
                    param_idx += 1
        
        self.trainer.model.load_state_dict(state_dict)
    
    def evaluate(self, server_round, parameters):
        """æœåŠ¡å™¨ç«¯è¯„ä¼°"""
        print(f"\nğŸ” Round {server_round}: Server evaluation")
        
        # æ›´æ–°æ¨¡å‹å‚æ•°
        if parameters:
            aggregated_weights = fl.common.parameters_to_ndarrays(parameters)
            self.update_global_model(aggregated_weights)
        
        # æ‰§è¡Œè¯„ä¼°
        try:
            accuracy, error_rate, f1_score = self.trainer.test(is_global=True, current_epoch=server_round)
            
            metrics = {
                "accuracy": accuracy,
                "error_rate": error_rate,
                "f1_score": f1_score
            }
            
            print(f"   ğŸ“ˆ Server metrics: {metrics}")
            return 0.0, metrics  # loss, metrics
            
        except Exception as e:
            print(f"   âŒ Server evaluation failed: {e}")
            return 0.0, {}

def create_config(args):
    """åˆ›å»ºé…ç½®"""
    cfg = get_cfg_default()
    extend_cfg(cfg)
    
    # è®¾ç½®åŸºæœ¬é…ç½®
    cfg.TRAINER.NAME = args.trainer
    cfg.DATASET.NAME = args.dataset
    cfg.DATASET.USERS = args.num_clients
    cfg.DATASET.IID = args.iid
    cfg.MODEL.BACKBONE.NAME = args.backbone
    cfg.OPTIM.ROUND = args.rounds
    cfg.OPTIM.MAX_EPOCH = args.local_epochs
    cfg.DATALOADER.TRAIN_X.BATCH_SIZE = args.batch_size
    cfg.DATALOADER.NUM_WORKERS = 0
    cfg.USE_CUDA = False
    
    # Trainerç‰¹å®šé…ç½®
    if args.trainer == "PromptFL":
        cfg.TRAINER.PROMPTFL.N_CTX = args.n_ctx
        cfg.TRAINER.PROMPTFL.PREC = "fp32"
    elif args.trainer == "CoOp":
        cfg.TRAINER.COOP.N_CTX = args.n_ctx
        cfg.TRAINER.COOP.PREC = "fp32"
    elif args.trainer == "Baseline":
        cfg.TRAINER.BASELINE.PREC = "fp32"
    
    cfg.freeze()
    return cfg

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="PromptFL with Flower - Docker Server")
    
    # æœåŠ¡å™¨é…ç½®
    parser.add_argument("--host", type=str, default="0.0.0.0", help="Server host")
    parser.add_argument("--port", type=int, default=8080, help="Server port")
    parser.add_argument("--rounds", type=int, default=10, help="Number of rounds")
    parser.add_argument("--min-clients", type=int, default=2, help="Minimum number of clients")
    
    # æ¨¡å‹é…ç½®
    parser.add_argument("--trainer", type=str, default="PromptFL", 
                       choices=["PromptFL", "CoOp", "Baseline"], help="Trainer type")
    parser.add_argument("--dataset", type=str, default="cifar10", help="Dataset name")
    parser.add_argument("--backbone", type=str, default="ViT-B/16", help="CLIP backbone")
    parser.add_argument("--n-ctx", type=int, default=16, help="Number of context tokens")
    
    # è®­ç»ƒé…ç½®
    parser.add_argument("--num-clients", type=int, default=2, help="Number of clients")
    parser.add_argument("--local-epochs", type=int, default=5, help="Local epochs")
    parser.add_argument("--batch-size", type=int, default=32, help="Batch size")
    parser.add_argument("--iid", action="store_true", help="IID data distribution")
    
    args = parser.parse_args()
    
    print("ğŸŒ¸ PromptFL with Flower - Docker Server")
    print("=" * 50)
    print(f"Host: {args.host}:{args.port}")
    print(f"Trainer: {args.trainer}")
    print(f"Dataset: {args.dataset}")
    print(f"Backbone: {args.backbone}")
    print(f"Rounds: {args.rounds}")
    print(f"Min Clients: {args.min_clients}")
    
    # åˆ›å»ºé…ç½®
    cfg = create_config(args)
    
    # åˆ›å»ºç­–ç•¥
    strategy = PromptFLStrategy(
        cfg=cfg,
        fraction_fit=1.0,
        fraction_evaluate=1.0,
        min_fit_clients=args.min_clients,
        min_evaluate_clients=args.min_clients,
        min_available_clients=args.min_clients,
    )
    
    # å¯åŠ¨æœåŠ¡å™¨
    print(f"\nğŸš€ Starting Flower server on {args.host}:{args.port}")
    
    fl.server.start_server(
        server_address=f"{args.host}:{args.port}",
        config=fl.server.ServerConfig(num_rounds=args.rounds),
        strategy=strategy,
    )

if __name__ == "__main__":
    main()